{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "autoencoder: https://towardsdatascience.com/applied-deep-learning-part-3-autoencoders-1c083af4d798 \\\n",
    "autoencoder: https://github.com/ardendertat/Applied-Deep-Learning-with-Keras/blob/master/notebooks/Part%203%20-%20Autoencoders.ipynb \\\n",
    "Unet: https://towardsdatascience.com/unet-line-by-line-explanation-9b191c76baf5 \\\n",
    "Convolutional autoencoder maths: https://pgaleone.eu/neural-networks/2016/11/24/convolutional-autoencoders/ \\\n",
    "Convolutional autoencoder code: https://blog.keras.io/building-autoencoders-in-keras.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import keras\n",
    "import os, os.path\n",
    "import tensorflow as tf\n",
    "from keras import layers\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Input\n",
    "from keras.datasets import mnist\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import TensorBoard\n",
    "from IPython.display import clear_output\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from keras.layers import Dropout\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeLines(array):\n",
    "#     lineStart=5\n",
    "#     lineEnd=18\n",
    "#     arrayLines=np.copy(array)\n",
    "#     for i in range(lineStart, lineEnd):\n",
    "#         arrayLines[i] = np.full_like(array[i], np.nan)\n",
    "#     return arrayLines\n",
    "    specificLinesIndexes = np.array([2,5,6,9,10,11,14,17,19])\n",
    "    arrayLines=np.copy(array)\n",
    "    for index in specificLinesIndexes:\n",
    "        arrayLines[index] = np.full_like(array[index], np.nan)\n",
    "    return arrayLines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "numberOfFiles=0\n",
    "try: \n",
    "    filesXtrain = os.listdir('../TrainingDataset/x_train/'); \n",
    "    numberOfFiles = len(filesXtrain)\n",
    "except: print('File not found')\n",
    "numberOfFiles-=1\n",
    "testingSetSize = 100\n",
    "mx_train_lines = np.empty((numberOfFiles-testingSetSize,24,144))\n",
    "mx_train = np.empty((numberOfFiles-testingSetSize,24,144))\n",
    "mx_train_lines_nan = np.empty((numberOfFiles-testingSetSize,24,144))\n",
    "mx_test_lines = np.empty((testingSetSize,24,144))\n",
    "mx_test_lines_nan = np.empty((testingSetSize,24,144))\n",
    "mx_test = np.empty((testingSetSize,24,144))\n",
    "mx_test_infos = np.empty((testingSetSize,7), dtype=\"O\")\n",
    "mx_test_base = np.empty((testingSetSize,24,144))\n",
    "allArrays = []\n",
    "for i in range(numberOfFiles):\n",
    "    allArrays.append(np.load('../TrainingDataset/x_train/Y2_{}.npy'.format(i), allow_pickle=True, encoding=\"latin1\"))\n",
    "allArrays = np.asarray(allArrays)\n",
    "\n",
    "for i in range(0,numberOfFiles-testingSetSize):\n",
    "    mx_train[i] = allArrays[i][1]\n",
    "    mx_train_lines[i] = makeLines(mx_train[i])\n",
    "    mx_train_lines_nan[i] = makeLines(mx_train[i])\n",
    "for i in range(numberOfFiles-testingSetSize,numberOfFiles):\n",
    "    mx_test[i-(numberOfFiles-testingSetSize)-1] = allArrays[i][1]\n",
    "    mx_test_lines[i-(numberOfFiles-testingSetSize)-1] = makeLines(mx_test[i-(numberOfFiles-testingSetSize)-1])\n",
    "    mx_test_lines_nan[i-(numberOfFiles-testingSetSize)-1] = makeLines(mx_test[i-(numberOfFiles-testingSetSize)-1])\n",
    "    mx_test_infos[i-(numberOfFiles-testingSetSize)-1] = allArrays[i][2]\n",
    "    mx_test_base[i-(numberOfFiles-testingSetSize)-1] = allArrays[i][0]\n",
    "\n",
    "mx_train_lines=np.nan_to_num(mx_train_lines)\n",
    "mx_train=np.nan_to_num(mx_train)\n",
    "mx_test_lines=np.nan_to_num(mx_test_lines)\n",
    "mx_test=np.nan_to_num(mx_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_encoder = keras.models.Sequential([\n",
    "    keras.layers.Reshape([24, 144, 1], input_shape=[24, 144], name=\"1\"),\n",
    "    keras.layers.Conv2D(32, kernel_size=3, padding=\"SAME\", activation=\"relu\", name=\"2_First_convolution\"),\n",
    "    keras.layers.Dropout(0.001, name=\"3_First_Dropout\"),\n",
    "    keras.layers.MaxPool2D(pool_size=2, name=\"4_First_Max_Pooling\"),\n",
    "    keras.layers.Conv2D(64, kernel_size=3, padding=\"SAME\", activation=\"relu\", name=\"5_Second_Convolution\"),\n",
    "    keras.layers.MaxPool2D(pool_size=2, name=\"6_Second_Max_Pooling\"),\n",
    "    keras.layers.Conv2D(128, kernel_size=3, padding=\"SAME\", activation=\"relu\", name=\"7_Third_Convolution\"),\n",
    "])\n",
    "conv_decoder = keras.models.Sequential([\n",
    "    keras.layers.Dense(128, input_shape=[6, 36, 128], name=\"1_Neural_Layer_128\"),\n",
    "    keras.layers.Conv2DTranspose(128, kernel_size=2, strides=2, padding=\"VALID\", activation=\"relu\", name=\"2_First_Conv2DTranspose\"),\n",
    "    keras.layers.Conv2DTranspose(64, kernel_size=1, strides=1, padding=\"SAME\", activation=\"relu\", name=\"3_Second_Conv2DTranspose\"),\n",
    "    keras.layers.Dropout(0.001, name=\"4_First_Dropout\"),\n",
    "    keras.layers.Conv2DTranspose(64, kernel_size=3, strides=2, padding=\"SAME\", activation=\"relu\", name=\"5_Third_Conv2DTranspose\"),\n",
    "    keras.layers.Conv2DTranspose(32, kernel_size=1, strides=1, padding=\"SAME\", activation=\"relu\", name=\"6_Fourth_Conv2DTranspose\"),\n",
    "    keras.layers.Conv2DTranspose(1, kernel_size=1, strides=1, padding=\"SAME\", activation=\"sigmoid\", name=\"7_Fifth_Conv2DTranspose\"),\n",
    "    keras.layers.Reshape([24, 144], name=\"8_Reshape_Output\")\n",
    "])\n",
    "conv_ae = keras.models.Sequential([conv_encoder, conv_decoder])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "100/100 [==============================] - 3s 28ms/step - loss: 0.0052\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7fa8876e9c90>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opt = keras.optimizers.Adam(learning_rate=0.001)\n",
    "conv_ae.compile(loss=\"mse\", optimizer=opt)\n",
    "conv_ae.fit(mx_train_lines, mx_train, epochs=20, batch_size=64, shuffle=True, callbacks=[CustomCallback()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomCallback(keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        numberOfPlots = 10\n",
    "        testPlotsIndex = []\n",
    "        for i in range(numberOfPlots):\n",
    "            while(True):\n",
    "                rand = np.random.randint(0, mx_test_base.shape[0]-10)\n",
    "                if rand not in testPlotsIndex:\n",
    "                    break\n",
    "            testPlotsIndex.append(rand)        \n",
    "        testPlotsIndex = np.asarray(testPlotsIndex)    \n",
    "        m=0\n",
    "        for y in testPlotsIndex:\n",
    "            prediction = conv_ae.predict(np.expand_dims(mx_test_lines[y],0)).reshape(24,144)\n",
    "            overlayedTruth = mx_test_lines[y].copy()\n",
    "            for i in range(mx_test_lines_nan[y].shape[0]):\n",
    "                if math.isnan(np.sum(mx_test_lines_nan[y][i])):\n",
    "                    overlayedTruth[i] = prediction[i]\n",
    "\n",
    "            finalArray = np.array([mx_test_base[y], mx_test[y], mx_test_lines_nan[y], overlayedTruth, mx_test_infos[y]])\n",
    "            np.save(\"AE_training_results/AE_training_epoch{}_matrix{}\".format(epoch, m), finalArray)\n",
    "            m+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
